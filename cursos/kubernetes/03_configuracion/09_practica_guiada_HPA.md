# Pr√°ctica guiada: emprego do HPA

Imos empregar un HPA para controlar a carga dun deployment sinxelo. 

## 1. Preparativos üõ´

- Imos partir dun namespace novo no noso cluster: **hpa**

```bash

kubectl create namespace hpa 

```

- Agora imos despregar un deployment que te√±a unha aplicaci√≥n de emprego intensivo de cpu

```yaml

#
# Imos crear un deploy para a aplicaci√≥n
#

apiVersion: apps/v1
kind: Deployment
metadata:
  name: cpu-intensive
  labels:
    app: cpu-intensive
    concern: test
spec:
  selector:
    matchLabels:
      app: cpu-intensive
      concern: test
  template:
    metadata:
      labels:
        app: cpu-intensive
        concern: test
    spec:
      containers:
      - name: app
        image: frmadem/k8s-training-cpu-intensive-app:v1
        ports:
        - containerPort: 8080

```
- Abrimoslle tr√°fico mediante un service:

```yaml

#
# Abr√≠moslle tr√°fico mediante un service
#

apiVersion: v1
kind: Service
metadata:
  name: cpu-intensive
spec:
  selector:
    app: cpu-intensive
    concern: test
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8080

```

√â interesante ver c√≥mo non definimos o campo __replicas__ no deployment. A raz√≥n √© que non queremos que interferir co traballo do HPA. 

Agora se aplicamos isto co kubectl:

```yaml

kubectl create -f <ficheiros yaml> -n hpa

```

Veremos que temos un service e un deployment con 0 r√©plicas. 

Imos facer que esto comece a andar!!!


## 2. O noso servidor de m√©tricas ‚è±

Para esta pr√°ctica imos empregar m√©tricas de tipo resource. Polo tanto necesitamos unha peza ou elemento que recolla m√©tricas do cl√∫ster e as sirva nunha das Layer do Api de kubernetes (concretamente no metrics.k8s.io).


Un elemento que nos pode servir √© o [metrics server](https://github.com/kubernetes-sigs/metrics-server).

Para instalalo imos empregar [Helm]():

```yaml

# instalar helm (se non o est√° instalado)
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

# empregamos o chart para lanzar o metrics-server
helm repo add metrics-server https://kubernetes-sigs.github.io/metrics-server/

helm upgrade --install metrics-server metrics-server/metrics-server --set args="{--kubelet-insecure-tls}"

```

Se todo vai ben poderemos facer xa consultas √≥ api do noso cluster de probas (en Kind):

```
kubectl get --raw /apis/metrics.k8s.io/v1beta1/nodes/kind-control-plane | jq

# Obteremos algo parecido a esto

{
  "kind": "NodeMetrics",
  "apiVersion": "metrics.k8s.io/v1beta1",
  "metadata": {
    "name": "kind-control-plane",
    "creationTimestamp": "2022-02-02T10:14:14Z",
    "labels": {
      "beta.kubernetes.io/arch": "amd64",
      "beta.kubernetes.io/os": "linux",
      "kubernetes.io/arch": "amd64",
      "kubernetes.io/hostname": "kind-control-plane",
      "kubernetes.io/os": "linux",
      "node-role.kubernetes.io/control-plane": "",
      "node-role.kubernetes.io/master": "",
      "node.kubernetes.io/exclude-from-external-load-balancers": ""
    }
  },
  "timestamp": "2022-02-02T12:14:09Z",
  "window": "20.219s",
  "usage": {
    "cpu": "242713548n",
    "memory": "707676Ki"
  }
}

```

Xa temos un xeito de obter m√©tricas (CPU/Memoria) dos nosos pods!

√â o momento de arrancar un HPA para a nosa app. 

## 3. Definindo o HPA üìÉ

A nosa app fai un uso intensivo de CPU polo tanto √© a m√©trica clave para a controlar.

```yaml

apiVersion: autoscaling/v2beta2 # hai varias versi√≥ns en funcionamento a d√≠a de hoxe
kind: HorizontalPodAutoscaler

metadata:
  name: o-meu-hpa  

spec: 

  #-------------------------------------------------
  # Esta √© a parte de selecci√≥n de pods a escalar
  #-------------------------------------------------
  scaleTargetRef: 
    kind: Deployment
    name: cpu-intensive


  #-------------------------------------------------
  # Nesta parte establecemos os l√≠mites do escalado
  #-------------------------------------------------
  minReplicas: 1
  maxReplicas: 2

  
  #---------------------------------------------------
  # Nesta secci√≥n definimos os criterios (m√©tricas)
  # segundo as que escalar
  #---------------------------------------------------
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50  

```

Efectivamente, √≥ pouco tempo veremos que nos escala o deploy a 1 r√©plica. 

Non obstante, de consultar o estado do noso hpa obteremos o seguinte:

```bash
kubectl get hpa -n hpa

NAME        REFERENCE                  TARGETS         MINPODS   MAXPODS   REPLICAS   AGE
o-meu-hpa   Deployment/cpu-intensive   <unknown>/50%   1         10        1          2m41s
```

Por qu√©? A resposta √© que tarda un pouco en atopar m√©tricas, salvo que non est√© ben configurado. 

Agora, imos xerarlle tr√°fico:

```bash
# Exportamos √≥ noso service √≥ porto 8084

kubectl port-forward svc/cpu-intensive -n hpa 8084:80

```

E noutro terminal:

```bash
watch -n1 "curl localhost:8084/fibo/40"
```

Con isto comenzar√° a xerar tr√°fico o noso servidor. 

```bash
# este comando mantennos informados do estado
kubectl get hpa -n hpa -w                                                                          

NAME        REFERENCE                  TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
o-meu-hpa   Deployment/cpu-intensive   0%/50%    1         10        1          7m55s
o-meu-hpa   Deployment/cpu-intensive   208%/50%   1         10        1          8m
o-meu-hpa   Deployment/cpu-intensive   306%/50%   1         10        5          8m16s
o-meu-hpa   Deployment/cpu-intensive   186%/50%   1         10        7          8m31s
```

Vemos como o tr√°fico comeza a ser absorbido polas novas r√©plicas que o HPA vai levantando.

Deste xeito, chega un momento que volvemos a estar por debaixo 50% de media de consumo

```bash
kubectl get hpa -n hpa

NAME        REFERENCE                  TARGETS         MINPODS   MAXPODS   REPLICAS   AGE
o-meu-hpa   Deployment/cpu-intensive   306%/50%   1         10        5          8m16s
o-meu-hpa   Deployment/cpu-intensive   186%/50%   1         10        7          8m31s
o-meu-hpa   Deployment/cpu-intensive   58%/50%    1         10        7          8m46s
o-meu-hpa   Deployment/cpu-intensive   48%/50%    1         10        7          9m1s
o-meu-hpa   Deployment/cpu-intensive   51%/50%    1         10        7          9m16s
o-meu-hpa   Deployment/cpu-intensive   48%/50%    1         10        7          9m31s
o-meu-hpa   Deployment/cpu-intensive   48%/50%    1         10        7          10m
o-meu-hpa   Deployment/cpu-intensive   48%/50%    1         10        7          10m
o-meu-hpa   Deployment/cpu-intensive   49%/50%    1         10        7          10m
o-meu-hpa   Deployment/cpu-intensive   49%/50%    1         10        7          11m
o-meu-hpa   Deployment/cpu-intensive   47%/50%    1         10        7          11m
o-meu-hpa   Deployment/cpu-intensive   48%/50%    1         10        7          11m
o-meu-hpa   Deployment/cpu-intensive   52%/50%    1         10        7          11m
o-meu-hpa   Deployment/cpu-intensive   47%/50%    1         10        7          12m
``` 

Se paramos o curl que xera tr√°fico, o pouco tempo vemos que o n√∫mero de r√©plicas baixa:

```bash
NAME        REFERENCE                  TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
o-meu-hpa   Deployment/cpu-intensive   45%/50%   1         10        8          20m
o-meu-hpa   Deployment/cpu-intensive   32%/50%   1         10        8          20m
o-meu-hpa   Deployment/cpu-intensive   0%/50%    1         10        8          20m
o-meu-hpa   Deployment/cpu-intensive   0%/50%    1         10        8          25m
o-meu-hpa   Deployment/cpu-intensive   0%/50%    1         10        6          25m
o-meu-hpa   Deployment/cpu-intensive   0%/50%    1         10        4          25m
o-meu-hpa   Deployment/cpu-intensive   0%/50%    1         10        2          26m
o-meu-hpa   Deployment/cpu-intensive   0%/50%    1         10        1          26m

```
O HPA tardou aproximadamente 5 min e volver a po√±er as r√©plicas a 1. Podemos modificar este comportamento cunha secci√≥n __behavior__. 

4. A secci√≥n behavior: o control "fino" do noso HPA üî¨

**Nota:**: para poder facer esta secci√≥n, compre ter unha versi√≥n de K8s que o permita. Para comprobalo abonda con facer:

```yaml
# comprobar que est√° autoscaling/v2beta2

kubectl api-versions | grep autoscaling/v2beta2

autoscaling/v2beta2

```

E metemos os seguintes cambios na definici√≥n do noso HPA:

```yaml
apiVersion: autoscaling/v2beta2
kind: HorizontalPodAutoscaler

metadata:
  name: o-meu-hpa  

spec: 

  #-------------------------------------------------
  # Esta √© a parte de selecci√≥n de pods a escalar
  #-------------------------------------------------
  scaleTargetRef: 
    apiVersion: apps/v1
    kind: Deployment
    name: cpu-intensive


  #-------------------------------------------------
  # Nesta parte establecemos os l√≠mites do escalado
  #-------------------------------------------------
  minReplicas: 1
  maxReplicas: 10

  
  #---------------------------------------------------
  # Nesta secci√≥n definimos os criterios (m√©tricas)
  # segundo as que escalar
  #---------------------------------------------------
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50  

  #
  # Control da desescalada
  #
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 30
      policies:
      - type: Pods
        value: 5
        periodSeconds: 15

```


Nesta secci√≥n:

1. Establecemos unha pol√≠tica que permite baixar de 5 en 5 pods cada 15 seg. 
2. A vent√° de estabilizaci√≥n a baixamos a 30 seg. 

Agora, e co novo behavior que puxemos, o HPA √© quen de baixar a escal√≥ns de 5 pod en per√≠odos de 15 segundos. 

Despois de parchear o noso HPA con este behavior. 

Lanzamos carga ata que escale a 8 r√©plicas (co curl anterior). 

Cortamos o curl!. 

Se vemos o comportamento:

```bash
kubectl get hpa -n hpa -w                                                                        

NAME        REFERENCE                  TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
o-meu-hpa   Deployment/cpu-intensive   47%/50%   1         10        8          2m13s
o-meu-hpa   Deployment/cpu-intensive   42%/50%   1         10        8          2m19s
o-meu-hpa   Deployment/cpu-intensive   5%/50%    1         10        8          2m34s
o-meu-hpa   Deployment/cpu-intensive   0%/50%    1         10        7          2m49s
o-meu-hpa   Deployment/cpu-intensive   0%/50%    1         10        2          3m5s
o-meu-hpa   Deployment/cpu-intensive   0%/50%    1         10        1          3m25s

```

Como vemos baixou a 1 r√©plica nun minuto de tempo.




